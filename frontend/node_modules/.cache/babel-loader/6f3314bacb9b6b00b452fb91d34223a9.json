{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\n\nexport function schemaFromJSON(_schema) {\n  let dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\n\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\n\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\n\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\n\n\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\n\n\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce((fieldNodes, column) => [...fieldNodes, new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])), ...fieldNodesFromJSON(column['children'])], []);\n}\n/** @ignore */\n\n\nfunction buffersFromJSON(xs) {\n  let buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n\n  for (let i = -1, n = (xs || []).length; ++i < n;) {\n    const column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n\n  return buffers;\n}\n/** @ignore */\n\n\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\n\n\nexport function fieldFromJSON(_field, dictionaries) {\n  let id;\n  let keys;\n  let field;\n  let dictMeta;\n  let type;\n  let dictType; // If no dictionary encoding\n\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n\n  return field || null;\n}\n/** @ignore */\n\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\n\n\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\n\n\nfunction typeFromJSON(f, children) {\n  const typeId = f['type']['name'];\n\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n\n    case 'null':\n      return new Null();\n\n    case 'binary':\n      return new Binary();\n\n    case 'utf8':\n      return new Utf8();\n\n    case 'bool':\n      return new Bool();\n\n    case 'list':\n      return new List((children || [])[0]);\n\n    case 'struct':\n      return new Struct(children || []);\n\n    case 'struct_':\n      return new Struct(children || []);\n  }\n\n  switch (typeId) {\n    case 'int':\n      {\n        const t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n\n    case 'floatingpoint':\n      {\n        const t = f['type'];\n        return new Float(Precision[t['precision']]);\n      }\n\n    case 'decimal':\n      {\n        const t = f['type'];\n        return new Decimal(t['scale'], t['precision']);\n      }\n\n    case 'date':\n      {\n        const t = f['type'];\n        return new Date_(DateUnit[t['unit']]);\n      }\n\n    case 'time':\n      {\n        const t = f['type'];\n        return new Time(TimeUnit[t['unit']], t['bitWidth']);\n      }\n\n    case 'timestamp':\n      {\n        const t = f['type'];\n        return new Timestamp(TimeUnit[t['unit']], t['timezone']);\n      }\n\n    case 'interval':\n      {\n        const t = f['type'];\n        return new Interval(IntervalUnit[t['unit']]);\n      }\n\n    case 'union':\n      {\n        const t = f['type'];\n        return new Union(UnionMode[t['mode']], t['typeIds'] || [], children || []);\n      }\n\n    case 'fixedsizebinary':\n      {\n        const t = f['type'];\n        return new FixedSizeBinary(t['byteWidth']);\n      }\n\n    case 'fixedsizelist':\n      {\n        const t = f['type'];\n        return new FixedSizeList(t['listSize'], (children || [])[0]);\n      }\n\n    case 'map':\n      {\n        const t = f['type'];\n        return new Map_((children || [])[0], t['keysSorted']);\n      }\n  }\n\n  throw new Error(`Unrecognized type: \"${typeId}\"`);\n}","map":{"version":3,"sources":["ipc/metadata/json.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAS,MAAT,EAAiB,KAAjB,QAA8B,cAA9B;AACA,SACc,UADd,EAEI,IAFJ,EAEU,MAFV,EAEkB,OAFlB,EAE2B,eAF3B,EAGI,IAHJ,EAGU,aAHV,EAGyB,IAHzB,EAG+B,MAH/B,EAGuC,KAHvC,EAII,IAJJ,EAIU,IAJV,EAIgB,GAJhB,EAIqB,KAJrB,EAI4B,KAJ5B,EAImC,IAJnC,EAIyC,QAJzC,EAImD,SAJnD,EAI2E,KAJ3E,QAKO,YALP;AAOA,SAAS,eAAT,EAA0B,WAA1B,EAAuC,SAAvC,EAAkD,YAAlD,QAAsE,WAAtE;AACA,SAAS,QAAT,EAAmB,SAAnB,EAA8B,YAA9B,EAA4C,SAA5C,EAAuD,QAAvD,QAAuE,YAAvE;AAEA;;AACA,OAAM,SAAU,cAAV,CAAyB,OAAzB,EAAsF;EAAA,IAA/C,YAA+C,uEAAT,IAAI,GAAJ,EAAS;EACxF,OAAO,IAAI,MAAJ,CACH,oBAAoB,CAAC,OAAD,EAAU,YAAV,CADjB,EAEH,sBAAsB,CAAC,OAAO,CAAC,gBAAD,CAAR,CAFnB,EAGH,YAHG,CAAP;AAKH;AAED;;AACA,OAAM,SAAU,mBAAV,CAA8B,CAA9B,EAAoC;EACtC,OAAO,IAAI,WAAJ,CACH,CAAC,CAAC,OAAD,CADE,EAEH,kBAAkB,CAAC,CAAC,CAAC,SAAD,CAAF,CAFf,EAGH,eAAe,CAAC,CAAC,CAAC,SAAD,CAAF,CAHZ,CAAP;AAKH;AAED;;AACA,OAAM,SAAU,uBAAV,CAAkC,CAAlC,EAAwC;EAC1C,OAAO,IAAI,eAAJ,CACH,mBAAmB,CAAC,CAAC,CAAC,MAAD,CAAF,CADhB,EAEH,CAAC,CAAC,IAAD,CAFE,EAEM,CAAC,CAAC,SAAD,CAFP,CAAP;AAIH;AAED;;AACA,SAAS,oBAAT,CAA8B,OAA9B,EAA4C,YAA5C,EAAgF;EAC5E,OAAO,CAAC,OAAO,CAAC,QAAD,CAAP,IAAqB,EAAtB,EAA0B,MAA1B,CAAiC,OAAjC,EAA0C,GAA1C,CAA+C,CAAD,IAAY,KAAK,CAAC,QAAN,CAAe,CAAf,EAAkB,YAAlB,CAA1D,CAAP;AACH;AAED;;;AACA,SAAS,qBAAT,CAA+B,MAA/B,EAA4C,YAA5C,EAAgF;EAC5E,OAAO,CAAC,MAAM,CAAC,UAAD,CAAN,IAAsB,EAAvB,EAA2B,MAA3B,CAAkC,OAAlC,EAA2C,GAA3C,CAAgD,CAAD,IAAY,KAAK,CAAC,QAAN,CAAe,CAAf,EAAkB,YAAlB,CAA3D,CAAP;AACH;AAED;;;AACA,SAAS,kBAAT,CAA4B,EAA5B,EAAqC;EACjC,OAAO,CAAC,EAAE,IAAI,EAAP,EAAW,MAAX,CAA+B,CAAC,UAAD,EAAa,MAAb,KAA6B,CAC/D,GAAG,UAD4D,EAE/D,IAAI,SAAJ,CACI,MAAM,CAAC,OAAD,CADV,EAEI,iBAAiB,CAAC,MAAM,CAAC,UAAD,CAAP,CAFrB,CAF+D,EAM/D,GAAG,kBAAkB,CAAC,MAAM,CAAC,UAAD,CAAP,CAN0C,CAA5D,EAOJ,EAPI,CAAP;AAQH;AAED;;;AACA,SAAS,eAAT,CAAyB,EAAzB,EAAgE;EAAA,IAA5B,OAA4B,uEAAF,EAAE;;EAC5D,KAAK,IAAI,CAAC,GAAG,CAAC,CAAT,EAAY,CAAC,GAAG,CAAC,EAAE,IAAI,EAAP,EAAW,MAAhC,EAAwC,EAAE,CAAF,GAAM,CAA9C,GAAkD;IAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,CAAD,CAAjB;IACA,MAAM,CAAC,UAAD,CAAN,IAAsB,OAAO,CAAC,IAAR,CAAa,IAAI,YAAJ,CAAiB,OAAO,CAAC,MAAzB,EAAiC,MAAM,CAAC,UAAD,CAAN,CAAmB,MAApD,CAAb,CAAtB;IACA,MAAM,CAAC,MAAD,CAAN,IAAkB,OAAO,CAAC,IAAR,CAAa,IAAI,YAAJ,CAAiB,OAAO,CAAC,MAAzB,EAAiC,MAAM,CAAC,MAAD,CAAN,CAAe,MAAhD,CAAb,CAAlB;IACA,MAAM,CAAC,QAAD,CAAN,IAAoB,OAAO,CAAC,IAAR,CAAa,IAAI,YAAJ,CAAiB,OAAO,CAAC,MAAzB,EAAiC,MAAM,CAAC,QAAD,CAAN,CAAiB,MAAlD,CAAb,CAApB;IACA,MAAM,CAAC,MAAD,CAAN,IAAkB,OAAO,CAAC,IAAR,CAAa,IAAI,YAAJ,CAAiB,OAAO,CAAC,MAAzB,EAAiC,MAAM,CAAC,MAAD,CAAN,CAAe,MAAhD,CAAb,CAAlB;IACA,OAAO,GAAG,eAAe,CAAC,MAAM,CAAC,UAAD,CAAP,EAAqB,OAArB,CAAzB;EACH;;EACD,OAAO,OAAP;AACH;AAED;;;AACA,SAAS,iBAAT,CAA2B,QAA3B,EAA6C;EACzC,OAAO,CAAC,QAAQ,IAAI,EAAb,EAAiB,MAAjB,CAAwB,CAAC,GAAD,EAAM,GAAN,KAAc,GAAG,GAAG,EAAE,GAAG,KAAK,CAAV,CAA5C,EAA0D,CAA1D,CAAP;AACH;AAED;;;AACA,OAAM,SAAU,aAAV,CAAwB,MAAxB,EAAqC,YAArC,EAAyE;EAE3E,IAAI,EAAJ;EACA,IAAI,IAAJ;EACA,IAAI,KAAJ;EACA,IAAI,QAAJ;EACA,IAAI,IAAJ;EACA,IAAI,QAAJ,CAP2E,CAS3E;;EACA,IAAI,CAAC,YAAD,IAAiB,EAAE,QAAQ,GAAG,MAAM,CAAC,YAAD,CAAnB,CAArB,EAAyD;IACrD,IAAI,GAAG,YAAY,CAAC,MAAD,EAAS,qBAAqB,CAAC,MAAD,EAAS,YAAT,CAA9B,CAAnB;IACA,KAAK,GAAG,IAAI,KAAJ,CAAU,MAAM,CAAC,MAAD,CAAhB,EAA0B,IAA1B,EAAgC,MAAM,CAAC,UAAD,CAAtC,EAAoD,sBAAsB,CAAC,MAAM,CAAC,gBAAD,CAAP,CAA1E,CAAR;EACH,CAHD,CAIA;EACA;EACA;EACA;EAPA,KAQK,IAAI,CAAC,YAAY,CAAC,GAAb,CAAiB,EAAE,GAAG,QAAQ,CAAC,IAAD,CAA9B,CAAL,EAA4C;IAC7C;IACA,IAAI,GAAG,CAAC,IAAI,GAAG,QAAQ,CAAC,WAAD,CAAhB,IAAiC,iBAAiB,CAAC,IAAD,CAAlD,GAAoE,IAAI,KAAJ,EAA3E;IACA,YAAY,CAAC,GAAb,CAAiB,EAAjB,EAAqB,IAAI,GAAG,YAAY,CAAC,MAAD,EAAS,qBAAqB,CAAC,MAAD,EAAS,YAAT,CAA9B,CAAxC;IACA,QAAQ,GAAG,IAAI,UAAJ,CAAe,IAAf,EAAqB,IAArB,EAA2B,EAA3B,EAA+B,QAAQ,CAAC,WAAD,CAAvC,CAAX;IACA,KAAK,GAAG,IAAI,KAAJ,CAAU,MAAM,CAAC,MAAD,CAAhB,EAA0B,QAA1B,EAAoC,MAAM,CAAC,UAAD,CAA1C,EAAwD,sBAAsB,CAAC,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;EACH,CANI,CAOL;EACA;EARK,KASA;IACD;IACA,IAAI,GAAG,CAAC,IAAI,GAAG,QAAQ,CAAC,WAAD,CAAhB,IAAiC,iBAAiB,CAAC,IAAD,CAAlD,GAAoE,IAAI,KAAJ,EAA3E;IACA,QAAQ,GAAG,IAAI,UAAJ,CAAe,YAAY,CAAC,GAAb,CAAiB,EAAjB,CAAf,EAAsC,IAAtC,EAA4C,EAA5C,EAAgD,QAAQ,CAAC,WAAD,CAAxD,CAAX;IACA,KAAK,GAAG,IAAI,KAAJ,CAAU,MAAM,CAAC,MAAD,CAAhB,EAA0B,QAA1B,EAAoC,MAAM,CAAC,UAAD,CAA1C,EAAwD,sBAAsB,CAAC,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;EACH;;EACD,OAAO,KAAK,IAAI,IAAhB;AACH;AAED;;AACA,SAAS,sBAAT,CAAgC,SAAhC,EAAkD;EAC9C,OAAO,IAAI,GAAJ,CAAwB,MAAM,CAAC,OAAP,CAAe,SAAS,IAAI,EAA5B,CAAxB,CAAP;AACH;AAED;;;AACA,SAAS,iBAAT,CAA2B,KAA3B,EAAqC;EACjC,OAAO,IAAI,GAAJ,CAAQ,KAAK,CAAC,UAAD,CAAb,EAA2B,KAAK,CAAC,UAAD,CAAhC,CAAP;AACH;AAED;;;AACA,SAAS,YAAT,CAAsB,CAAtB,EAA8B,QAA9B,EAAgD;EAE5C,MAAM,MAAM,GAAG,CAAC,CAAC,MAAD,CAAD,CAAU,MAAV,CAAf;;EAEA,QAAQ,MAAR;IACI,KAAK,MAAL;MAAe,OAAO,IAAI,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAI,IAAJ,EAAP;;IACf,KAAK,QAAL;MAAe,OAAO,IAAI,MAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAI,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAI,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAI,IAAJ,CAAS,CAAC,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,CAAP;;IACf,KAAK,QAAL;MAAe,OAAO,IAAI,MAAJ,CAAW,QAAQ,IAAI,EAAvB,CAAP;;IACf,KAAK,SAAL;MAAgB,OAAO,IAAI,MAAJ,CAAW,QAAQ,IAAI,EAAvB,CAAP;EARpB;;EAWA,QAAQ,MAAR;IACI,KAAK,KAAL;MAAY;QACR,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,GAAJ,CAAQ,CAAC,CAAC,UAAD,CAAT,EAAuB,CAAC,CAAC,UAAD,CAAxB,CAAP;MACH;;IACD,KAAK,eAAL;MAAsB;QAClB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,KAAJ,CAAU,SAAS,CAAC,CAAC,CAAC,WAAD,CAAF,CAAnB,CAAP;MACH;;IACD,KAAK,SAAL;MAAgB;QACZ,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,OAAJ,CAAY,CAAC,CAAC,OAAD,CAAb,EAAwB,CAAC,CAAC,WAAD,CAAzB,CAAP;MACH;;IACD,KAAK,MAAL;MAAa;QACT,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,KAAJ,CAAU,QAAQ,CAAC,CAAC,CAAC,MAAD,CAAF,CAAlB,CAAP;MACH;;IACD,KAAK,MAAL;MAAa;QACT,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,IAAJ,CAAS,QAAQ,CAAC,CAAC,CAAC,MAAD,CAAF,CAAjB,EAAqC,CAAC,CAAC,UAAD,CAAtC,CAAP;MACH;;IACD,KAAK,WAAL;MAAkB;QACd,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,SAAJ,CAAc,QAAQ,CAAC,CAAC,CAAC,MAAD,CAAF,CAAtB,EAA0C,CAAC,CAAC,UAAD,CAA3C,CAAP;MACH;;IACD,KAAK,UAAL;MAAiB;QACb,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,QAAJ,CAAa,YAAY,CAAC,CAAC,CAAC,MAAD,CAAF,CAAzB,CAAP;MACH;;IACD,KAAK,OAAL;MAAc;QACV,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,KAAJ,CAAU,SAAS,CAAC,CAAC,CAAC,MAAD,CAAF,CAAnB,EAAwC,CAAC,CAAC,SAAD,CAAD,IAAgB,EAAxD,EAA6D,QAAQ,IAAI,EAAzE,CAAP;MACH;;IACD,KAAK,iBAAL;MAAwB;QACpB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,eAAJ,CAAoB,CAAC,CAAC,WAAD,CAArB,CAAP;MACH;;IACD,KAAK,eAAL;MAAsB;QAClB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,aAAJ,CAAkB,CAAC,CAAC,UAAD,CAAnB,EAAiC,CAAC,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAjC,CAAP;MACH;;IACD,KAAK,KAAL;MAAY;QACR,MAAM,CAAC,GAAG,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI,IAAJ,CAAS,CAAC,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,EAA8B,CAAC,CAAC,YAAD,CAA/B,CAAP;MACH;EA5CL;;EA8CA,MAAM,IAAI,KAAJ,CAAU,uBAAuB,MAAM,GAAvC,CAAN;AACH","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"]},"metadata":{},"sourceType":"module"}